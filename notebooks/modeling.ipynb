{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Kostas\n",
    "\n",
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "sys.path.insert(1, 'C:\\\\Users\\\\Administrator\\\\Documents\\\\Python Code\\\\Big Data & AI Academy\\\\Live Training\\\\Exercises\\\\Project\\\\src')\n",
    "from preprocessing import run_preprocessing_pipeline\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path = Path(cwd)\n",
    "path = str(path.parent.absolute())\n",
    "\n",
    "df_initial = pd.read_csv(path + '\\data\\\\listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>availability_30</th>\n",
       "      <th>availability_60</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_of_reviews_ltm</th>\n",
       "      <th>number_of_reviews_l30d</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>37.98863</td>\n",
       "      <td>23.76527</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>79</td>\n",
       "      <td>170</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>37.98903</td>\n",
       "      <td>23.76448</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>86</td>\n",
       "      <td>361</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>37.98888</td>\n",
       "      <td>23.76473</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>331</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>37.98903</td>\n",
       "      <td>23.76448</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>82</td>\n",
       "      <td>357</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.33</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>329</td>\n",
       "      <td>37.98924</td>\n",
       "      <td>23.76500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "      <td>208</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_since  host_response_time  host_response_rate  host_is_superhost  \\\n",
       "0        2009                   0                 0.0                  1   \n",
       "1        2009                   0                 0.0                  1   \n",
       "2        2009                   0                 0.0                  1   \n",
       "3        2009                   0                 0.0                  1   \n",
       "4        2009                   0                 0.0                  1   \n",
       "\n",
       "   host_listings_count  host_has_profile_pic  host_identity_verified  \\\n",
       "0                  6.0                     1                       1   \n",
       "1                  6.0                     1                       1   \n",
       "2                  6.0                     1                       1   \n",
       "3                  6.0                     1                       1   \n",
       "4                  6.0                     1                       1   \n",
       "\n",
       "   neighbourhood_cleansed  latitude  longitude  ...  availability_30  \\\n",
       "0                     329  37.98863   23.76527  ...               19   \n",
       "1                     329  37.98903   23.76448  ...               26   \n",
       "2                     329  37.98888   23.76473  ...               15   \n",
       "3                     329  37.98903   23.76448  ...               22   \n",
       "4                     329  37.98924   23.76500  ...                0   \n",
       "\n",
       "   availability_60  availability_90  availability_365  number_of_reviews  \\\n",
       "0               49               79               170                 32   \n",
       "1               56               86               361                 52   \n",
       "2               26               56               331                 71   \n",
       "3               52               82               357                 24   \n",
       "4               27               57               208                 17   \n",
       "\n",
       "   number_of_reviews_ltm  number_of_reviews_l30d  instant_bookable  \\\n",
       "0                      7                       0                 1   \n",
       "1                     12                       1                 1   \n",
       "2                     19                       3                 1   \n",
       "3                      1                       0                 1   \n",
       "4                      0                       0                 1   \n",
       "\n",
       "   reviews_per_month  target  \n",
       "0               0.41    79.0  \n",
       "1               0.72    50.0  \n",
       "2               0.97    38.0  \n",
       "3               0.33    48.0  \n",
       "4               0.23    47.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = run_preprocessing_pipeline(df_initial)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target.\n",
    "X = df.drop('target', axis = 1, inplace = False)\n",
    "y = df.target\n",
    "\n",
    "# Split into train and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# Remove outliers from training set.\n",
    "price_threshold = 200\n",
    "\n",
    "X_train.reset_index(drop = True, inplace = True)\n",
    "y_train.reset_index(drop = True, inplace = True)\n",
    "\n",
    "indices = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] <= price_threshold:\n",
    "        indices.append(i)\n",
    "\n",
    "X_train = X_train.iloc[indices, :]\n",
    "y_train = y_train.iloc[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Validation score MAE: 24.04077027873194\n",
      "Average Cross-Validation score MAPE: 0.432500154297251\n",
      "MAE:  38.19\n",
      "MAPE:  0.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create and fit model.\n",
    "model_dt = DecisionTreeRegressor(criterion = 'absolute_error')\n",
    "\n",
    "scores = cross_val_score(model_dt, X_train, y_train, scoring = 'neg_mean_absolute_error', cv = 7)\n",
    "print(f'Average Cross-Validation score MAE: {-1 * scores.mean()}')\n",
    "\n",
    "scores = cross_val_score(model_dt, X_train, y_train, scoring = 'neg_mean_absolute_percentage_error', cv = 7)\n",
    "print(f'Average Cross-Validation score MAPE: {-1 * scores.mean()}')\n",
    "\n",
    "model_dt.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on test set.\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "# Calculate MAE and MAPE.\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "mape_dt = mean_absolute_percentage_error(y_test, y_pred_dt)\n",
    "\n",
    "print(f'MAE: {mae_dt : .2f}')\n",
    "print(f'MAPE: {mape_dt : .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Validation score MAE: 27.532593632963493\n",
      "Average Cross-Validation score MAPE: 0.5530331282130986\n",
      "MAE:  35.32\n",
      "MAPE:  0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create and fit model.\n",
    "model_lr = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(model_lr, X_train, y_train, scoring = 'neg_mean_absolute_error', cv = 7)\n",
    "print(f'Average Cross-Validation score MAE: {-1 * scores.mean()}')\n",
    "\n",
    "scores = cross_val_score(model_lr, X_train, y_train, scoring = 'neg_mean_absolute_percentage_error', cv = 7)\n",
    "print(f'Average Cross-Validation score MAPE: {-1 * scores.mean()}')\n",
    "\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on test set.\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Calculate MAE and MAPE.\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "mape_lr = mean_absolute_percentage_error(y_test, y_pred_lr)\n",
    "\n",
    "print(f'MAE: {mae_lr : .2f}')\n",
    "print(f'MAPE: {mape_lr : .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Validation score: 17.203669839879115\n",
      "Average Cross-Validation score MAPE: 0.3281736493994804\n",
      "MAE:  31.55\n",
      "MAPE:  0.36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create and fit model.\n",
    "model_rf = RandomForestRegressor()\n",
    "scores = cross_val_score(model_rf, X_train, y_train, scoring = 'neg_mean_absolute_error', cv = 7)\n",
    "print(f'Average Cross-Validation score: {-1 * scores.mean()}')\n",
    "\n",
    "scores = cross_val_score(model_rf, X_train, y_train, scoring = 'neg_mean_absolute_percentage_error', cv = 7)\n",
    "print(f'Average Cross-Validation score MAPE: {-1 * scores.mean()}')\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on test set.\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Calculate MAE and MAPE.\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mape_rf = mean_absolute_percentage_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f'MAE: {mae_rf : .2f}')\n",
    "print(f'MAPE: {mape_rf : .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Validation score: 17.264341968539718\n",
      "Average Cross-Validation score MAPE: 0.32658132569308357\n",
      "MAE:  30.83\n",
      "MAPE:  0.34\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Create and fit model.\n",
    "model_xgb = XGBRegressor()\n",
    "\n",
    "scores = cross_val_score(model_xgb, X_train, y_train, scoring = 'neg_mean_absolute_error', cv = 7)\n",
    "print(f'Average Cross-Validation score: {-1 * scores.mean()}')\n",
    "\n",
    "scores = cross_val_score(model_xgb, X_train, y_train, scoring = 'neg_mean_absolute_percentage_error', cv = 7)\n",
    "print(f'Average Cross-Validation score MAPE: {-1 * scores.mean()}')\n",
    "\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on test set.\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Calculate MAE and MAPE.\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mape_xgb = mean_absolute_percentage_error(y_test, y_pred_xgb)\n",
    "\n",
    "print(f'MAE: {mae_xgb : .2f}')\n",
    "print(f'MAPE: {mape_xgb : .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning\n",
    "\n",
    "Use Grid Search to tune the model\n",
    "\n",
    "1. Find optimal n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    random_state=None, reg_alpha=None,\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             param_grid={'colsample_bytree': [0.8], 'gamma': [0],\n",
       "                         'learning_rate': [0.1], 'max_depth': [5],\n",
       "                         'min_child_weight': [1],\n",
       "                         'n_estimators': range(100, 650, 50), 'n_jobs': [4],\n",
       "                         'scale_pos_weight': [1], 'subsample': [0.8]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_tuned = XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators' : range(100, 650, 50), 'learning_rate' : [0.1], 'max_depth' : [5], 'min_child_weight' : [1], 'gamma' : [0], \n",
    "              'subsample' : [0.8], 'colsample_bytree' : [0.8], 'n_jobs' : [4], 'scale_pos_weight' : [1]}\n",
    "\n",
    "grid = GridSearchCV(model_xgb_tuned, param_grid, cv = 5, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of estimators: 300\n",
      "Best MAE: 16.934506169407275\n"
     ]
    }
   ],
   "source": [
    "print(f'Best number of estimators: {grid.best_estimator_.n_estimators}')\n",
    "print(f'Best MAE: {-1 * grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Find optimal max_depth and min_child_weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8], 'gamma': [0],\n",
       "                         'learning_rate': [0.1], 'max_depth': range(3, 10),\n",
       "                         'min_child_weight': range(1, 6), 'n_estimators': [300],\n",
       "                         'n_jobs': [4], 'scale_pos_weight': [1],\n",
       "                         'subsample': [0.8]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_tuned = XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators' : [300], 'learning_rate' : [0.1], 'max_depth' : range(3, 10), 'min_child_weight' : range(1, 6), 'gamma' : [0], \n",
    "              'subsample' : [0.8], 'colsample_bytree' : [0.8], 'n_jobs' : [4], 'scale_pos_weight' : [1]}\n",
    "\n",
    "grid = GridSearchCV(model_xgb_tuned, param_grid, cv = 5, scoring = 'neg_mean_absolute_error', n_jobs = -1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max depth: 7\n",
      "Best min child weight: 2\n",
      "Best MAE: 16.7415625575158\n"
     ]
    }
   ],
   "source": [
    "print(f'Best max depth: {grid.best_estimator_.max_depth}')\n",
    "print(f'Best min child weight: {grid.best_estimator_.min_child_weight}')\n",
    "print(f'Best MAE: {-1 * grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find optimal gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8],\n",
       "                         'gamma': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                         'learning_rate': [0.1], 'max_depth': [7],\n",
       "                         'min_child_weight': [2], 'n_estimators': [300],\n",
       "                         'n_jobs': [4], 'scale_pos_weight': [1],\n",
       "                         'subsample': [0.8]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_tuned = XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators' : [300], 'learning_rate' : [0.1], 'max_depth' : [7], 'min_child_weight' : [2], 'gamma' : [i/10.0 for i in range(0, 6)], \n",
    "              'subsample' : [0.8], 'colsample_bytree' : [0.8], 'n_jobs' : [4], 'scale_pos_weight' : [1]}\n",
    "\n",
    "grid = GridSearchCV(model_xgb_tuned, param_grid, cv = 5, scoring = 'neg_mean_absolute_error', n_jobs = -1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best gamma: 0.5\n",
      "Best MAE: 16.73508294171928\n"
     ]
    }
   ],
   "source": [
    "print(f'Best gamma: {grid.best_estimator_.gamma}')\n",
    "print(f'Best MAE: {-1 * grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Recalibrate optimal n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8], 'gamma': [0.5],\n",
       "                         'learning_rate': [0.1], 'max_depth': [7],\n",
       "                         'min_child_weight': [2],\n",
       "                         'n_estimators': range(100, 650, 50), 'n_jobs': [4],\n",
       "                         'scale_pos_weight': [1], 'subsample': [0.8]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_tuned = XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators' : range(100, 650, 50), 'learning_rate' : [0.1], 'max_depth' : [7], 'min_child_weight' : [2], 'gamma' : [0.5], \n",
    "              'subsample' : [0.8], 'colsample_bytree' : [0.8], 'n_jobs' : [4], 'scale_pos_weight' : [1]}\n",
    "\n",
    "grid = GridSearchCV(model_xgb_tuned, param_grid, cv = 5, scoring = 'neg_mean_absolute_error', n_jobs = -1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of estimators: 200\n",
      "Best MAE: 16.68390879699337\n"
     ]
    }
   ],
   "source": [
    "print(f'Best number of estimators: {grid.best_estimator_.n_estimators}')\n",
    "print(f'Best MAE: {-1 * grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Find optimal subsample and colsample_bytree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
       "                         'gamma': [0.5], 'learning_rate': [0.1],\n",
       "                         'max_depth': [7], 'min_child_weight': [2],\n",
       "                         'n_estimators': [200], 'n_jobs': [4],\n",
       "                         'scale_pos_weight': [1],\n",
       "                         'subsample': [0.6, 0.7, 0.8, 0.9]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_tuned = XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators' : [200], 'learning_rate' : [0.1], 'max_depth' : [7], 'min_child_weight' : [2], 'gamma' : [0.5], \n",
    "              'subsample' : [i/10.0 for i in range(6,10)], 'colsample_bytree' : [i/10.0 for i in range(6,10)], 'n_jobs' : [4], 'scale_pos_weight' : [1]}\n",
    "\n",
    "grid = GridSearchCV(model_xgb_tuned, param_grid, cv = 5, scoring = 'neg_mean_absolute_error', n_jobs = -1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best subsample: 0.8\n",
      "Best colsample bytree: 0.8\n",
      "Best MAE: 16.68390879699337\n"
     ]
    }
   ],
   "source": [
    "print(f'Best subsample: {grid.best_estimator_.subsample}')\n",
    "print(f'Best colsample bytree: {grid.best_estimator_.colsample_bytree}')\n",
    "print(f'Best MAE: {-1 * grid.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.75, 0.8, 0.85], 'gamma': [0.5],\n",
       "                         'learning_rate': [0.1], 'max_depth': [7],\n",
       "                         'min_child_weight': [2], 'n_estimators': [200],\n",
       "                         'n_jobs': [4], 'scale_pos_weight': [1],\n",
       "                         'subsample': [0.75, 0.8, 0.85]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_tuned = XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators' : [200], 'learning_rate' : [0.1], 'max_depth' : [7], 'min_child_weight' : [2], 'gamma' : [0.5], \n",
    "              'subsample' : [i/100.0 for i in range(75,90,5)], 'colsample_bytree' : [i/100.0 for i in range(75,90,5)], 'n_jobs' : [4], 'scale_pos_weight' : [1]}\n",
    "\n",
    "grid = GridSearchCV(model_xgb_tuned, param_grid, cv = 5, scoring = 'neg_mean_absolute_error', n_jobs = -1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best subsample: 0.8\n",
      "Best colsample bytree: 0.8\n",
      "Best MAE: 16.68390879699337\n"
     ]
    }
   ],
   "source": [
    "print(f'Best subsample: {grid.best_estimator_.subsample}')\n",
    "print(f'Best colsample bytree: {grid.best_estimator_.colsample_bytree}')\n",
    "print(f'Best MAE: {-1 * grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Find optimal reg alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8], 'gamma': [0.5],\n",
       "                         'learning_rate': [0.1], 'max_depth': [7],\n",
       "                         'min_child_weight': [2], 'n_estimators': [200],\n",
       "                         'n_jobs': [4], 'reg_alpha': [1e-05, 0.01, 0.1, 1, 100],\n",
       "                         'scale_pos_weight': [1], 'subsample': [0.8]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_tuned = XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators' : [200], 'learning_rate' : [0.1], 'max_depth' : [7], 'min_child_weight' : [2], 'gamma' : [0.5], \n",
    "              'subsample' : [0.8], 'colsample_bytree' : [0.8], 'n_jobs' : [4], 'scale_pos_weight' : [1], 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]}\n",
    "\n",
    "grid = GridSearchCV(model_xgb_tuned, param_grid, cv = 5, scoring = 'neg_mean_absolute_error', n_jobs = -1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best reg alpha: 1e-05\n",
      "Best MAE: 16.68390880121172\n"
     ]
    }
   ],
   "source": [
    "print(f'Best reg alpha: {grid.best_estimator_.reg_alpha}')\n",
    "print(f'Best MAE: {-1 * grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Finally find optimal learning rate and number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8], 'gamma': [0.5],\n",
       "                         'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       "                                           0.07, 0.08, 0.09, 0.1],\n",
       "                         'max_depth': [7], 'min_child_weight': [2],\n",
       "                         'n_estimators': range(100, 1100, 100), 'n_jobs': [4],\n",
       "                         'reg_alpha': [1e-05], 'scale_pos_weight': [1],\n",
       "                         'subsample': [0.8]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_tuned = XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators' : range(100, 1100, 100), 'learning_rate' : [i/100.0 for i in range(1, 11)], 'max_depth' : [7], 'min_child_weight' : [2], 'gamma' : [0.5], \n",
    "              'subsample' : [0.8], 'colsample_bytree' : [0.8], 'n_jobs' : [4], 'scale_pos_weight' : [1], 'reg_alpha':[1e-5]}\n",
    "\n",
    "grid = GridSearchCV(model_xgb_tuned, param_grid, cv = 5, scoring = 'neg_mean_absolute_error', n_jobs = -1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of estimators: 900\n",
      "Best learning rate: 0.02\n",
      "Best MAE: 16.45838253881044\n"
     ]
    }
   ],
   "source": [
    "print(f'Best number of estimators: {grid.best_estimator_.n_estimators}')\n",
    "print(f'Best learning rate: {grid.best_estimator_.learning_rate}')\n",
    "print(f'Best MAE: {-1 * grid.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    enable_categorical=False, gamma=None,\n",
       "                                    gpu_id=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8], 'gamma': [0.5],\n",
       "                         'learning_rate': [0.015, 0.02, 0.025],\n",
       "                         'max_depth': [7], 'min_child_weight': [2],\n",
       "                         'n_estimators': [850, 900, 950], 'n_jobs': [4],\n",
       "                         'reg_alpha': [1e-05], 'scale_pos_weight': [1],\n",
       "                         'subsample': [0.8]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb_tuned = XGBRegressor()\n",
    "\n",
    "param_grid = {'n_estimators' : [850, 900, 950], 'learning_rate' : [0.015, 0.02, 0.025], 'max_depth' : [7], 'min_child_weight' : [2], 'gamma' : [0.5], \n",
    "              'subsample' : [0.8], 'colsample_bytree' : [0.8], 'n_jobs' : [4], 'scale_pos_weight' : [1], 'reg_alpha':[1e-5]}\n",
    "\n",
    "grid = GridSearchCV(model_xgb_tuned, param_grid, cv = 5, scoring = 'neg_mean_absolute_error', n_jobs = -1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of estimators: 950\n",
      "Best learning rate: 0.025\n",
      "Best MAE: 16.44011490414669\n"
     ]
    }
   ],
   "source": [
    "print(f'Best number of estimators: {grid.best_estimator_.n_estimators}')\n",
    "print(f'Best learning rate: {grid.best_estimator_.learning_rate}')\n",
    "print(f'Best MAE: {-1 * grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, enable_categorical=False,\n",
       "             gamma=0.5, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.025, max_delta_step=0,\n",
       "             max_depth=7, min_child_weight=2, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=950, n_jobs=4,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MAE: 16.44011490414669\n"
     ]
    }
   ],
   "source": [
    "print(f'Final MAE: {-1 * grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mean Absolute Error: 16.00458345245672\n",
      "Final Median Absolute Error: 10.792226791381836\n",
      "Final MAPE: 0.29479677199929366\n"
     ]
    }
   ],
   "source": [
    "# Create and fit model.\n",
    "model_xgb_final = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                               colsample_bynode=1, colsample_bytree=0.8, enable_categorical=False,\n",
    "                               gamma=0.5, gpu_id=-1, importance_type=None,\n",
    "                               interaction_constraints='', learning_rate=0.025, max_delta_step=0,\n",
    "                               max_depth=7, min_child_weight=2, monotone_constraints='()', \n",
    "                               n_estimators=950, n_jobs=4, num_parallel_tree=1, predictor='auto',\n",
    "                               random_state=0, reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=1, \n",
    "                               subsample=0.8, tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "# Mean Absolute Error\n",
    "scores = cross_val_score(model_xgb_final, X_train, y_train, scoring = 'neg_mean_absolute_error', cv = 10)\n",
    "\n",
    "print(f'Final Mean Absolute Error: {-1 * scores.mean()}')\n",
    "\n",
    "# Median Absolute Error\n",
    "scores = cross_val_score(model_xgb_final, X_train, y_train, scoring = 'neg_median_absolute_error', cv = 10)\n",
    "\n",
    "print(f'Final Median Absolute Error: {-1 * scores.mean()}')\n",
    "\n",
    "# Mean Absolute Percentage Error\n",
    "scores = cross_val_score(model_xgb_final, X_train, y_train, scoring = 'neg_mean_absolute_percentage_error', cv = 10)\n",
    "\n",
    "print(f'Final MAPE: {-1 * scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply on  test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics from applying model on test set:\n",
      "Mean Absolute Error:  29.89\n",
      "Median Absolute Error:  11.34\n",
      "Mean Absolute Percentage Error:  0.32\n"
     ]
    }
   ],
   "source": [
    "# Fit model.\n",
    "model_xgb_final.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions on test set.\n",
    "y_pred_xgb = model_xgb_final.predict(X_test)\n",
    "\n",
    "# Calculate MAE and MAPE.\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "medae_xgb = median_absolute_error(y_test, y_pred_xgb)\n",
    "mape_xgb = mean_absolute_percentage_error(y_test, y_pred_xgb)\n",
    "\n",
    "print('Metrics from applying model on test set:')\n",
    "print(f'Mean Absolute Error: {mae_xgb : .2f}')\n",
    "print(f'Median Absolute Error: {medae_xgb : .2f}')\n",
    "print(f'Mean Absolute Percentage Error: {mape_xgb : .2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\Administrator\\\\Documents\\\\Python Code\\\\Big Data & AI Academy\\\\Live Training\\\\Exercises\\\\Project\\\\models\\\\model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(model_xgb_final, path + '\\models\\\\model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Dimitris\n",
    "This script is used to perform grid search to find the optimal values for the hyper-parameters of 4 regression algorithm models.\n",
    "The models tried and their tuned hyperparameters are:\n",
    "1. Linear Regression |  ---\n",
    "2. Decision Tree &emsp;&nbsp;&nbsp;&nbsp;| max_depth:[5, 10, 15, 20, 40], min_samples_leaf:[1, 2, 4, 8]\n",
    "3. Random Forest &emsp;| tmax_depth:[5, 10, 15, 20, 40], n_estimators:[100, 200, 400, 800]\n",
    "4. XGBoost &emsp;&emsp;&emsp;&emsp;| max_depth:[5, 7, 8, 10, 15], n_estimators:[100, 200, 400, 800], learning_rate:[0.01, 0.05, 0.1, .2, .4, .8], colsample_bytree:[.5, .6, .8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calling the preprocessing function on the dataset. It returns the preprocessed dataset and a boolean informing the user of any existing NAN values.\n",
    "df = run_preprocessing_pipeline(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a single grid search function to call for each model. The outliers\n",
    "# (price>200) are droped only for the training sets.\n",
    "#--------------------------------------------------\n",
    "# Arguements\n",
    "# df:           The preprocessed dataframe.\n",
    "# model_arg:    The function defining the model e.g. RandomForestRegressor().\n",
    "# dict_params:  the parameters and their values to try in dictionary form.\n",
    "#--------------------------------------------------\n",
    "# Returns\n",
    "# grid:                             The grid containing the tried models and their metrics.\n",
    "# X_train, X_test, y_train, y_test  The split datasets originating from df.\n",
    "\n",
    "def employ_grid_search(df, model_arg, dict_params):\n",
    "    X = df.iloc[:,:-1].copy()\n",
    "    y = df.target.copy()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Removing outliers from training set only.\n",
    "    valid_indices = y_train[y_train <= 200].index\n",
    "    X_train = X_train.loc[valid_indices,:]\n",
    "    y_train = y_train.loc[valid_indices]\n",
    "\n",
    "    if os.cpu_count() > 2:\n",
    "        n_jobs = os.cpu_count() - 2\n",
    "        print(\"Using\",n_jobs,\"threads to parallelize grid search.\")\n",
    "    else:\n",
    "        n_jobs = 1\n",
    "    grid = GridSearchCV(model_arg, dict_params, cv = 10, verbose = 4,\n",
    "                        scoring = [\"neg_mean_absolute_error\",\"neg_median_absolute_error\",\"neg_mean_absolute_percentage_error\",\"neg_root_mean_squared_error\"], refit = False,\n",
    "                        n_jobs = n_jobs)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the grids\n",
    "\n",
    "#Linear Regression --- No grid search is needed but included here for perspective reasons.\n",
    "lin_reg_params = {\"normalize\":[True]}\n",
    "gridLR, X_trainLR, X_testLR, y_trainLR, y_testLR = employ_grid_search(df, LinearRegression(), lin_reg_params)\n",
    "\n",
    "#Random Forest\n",
    "rf_params = {'n_estimators':[100, 200, 400, 800], 'max_depth':[5, 10, 15, 20, 40]}\n",
    "gridRF, X_trainRF, X_testRF, y_trainRF, y_testRF = employ_grid_search(df, RandomForestRegressor(), rf_params)\n",
    "\n",
    "#Decision Tree\n",
    "tree_params = {'min_samples_leaf':[1, 2, 4, 8], 'max_depth':[5, 10, 15, 20, 40]}\n",
    "gridDT, X_trainDT, X_testDT, y_trainDT, y_testDT = employ_grid_search(df, DecisionTreeRegressor(), tree_params)\n",
    "\n",
    "#XGboost --- This can take some time to run due to multiple parameters tried. Uncomment if you want to run it.\n",
    "xgb_params = {'n_estimators' : [100, 200, 400, 800], 'learning_rate' : [.01, .05, .1, .2, .4, .8], 'max_depth' : [5, 7, 8, 10, 15], 'colsample_bytree' : [.5, .6, .8]}\n",
    "gridXGB, X_trainXGB, X_testXGB, y_trainXGB, y_testXGB = employ_grid_search(df, XGBRegressor(), xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the best model parameters based on score achieved durring cross-validation. It is chosen from the top 5 models\n",
    "# based on rmse and mae.\n",
    "\n",
    "for gs in [gridLR, gridRF, gridDT, gridXGB]:\n",
    "    temp = pd.DataFrame(gs.cv_results_)\n",
    "    for metric in [\"mean_test_neg_mean_absolute_error\", \"mean_test_neg_root_mean_squared_error\"]:\n",
    "        selected_params = temp.loc[temp.loc[:,metric].apply(lambda x: -x).sort_values(ascending = True).index.values[0:5],\"params\"]\n",
    "        for i in selected_params:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the 2 best models (the difference is in the number of features as the input)\n",
    "#with the optimal values for the hyperparameters as found through grid search.\n",
    "\n",
    "modelLR = LinearRegression(normalize = True)\n",
    "modelTree = DecisionTreeRegressor(min_samples_leaf=8, max_depth=10)\n",
    "modelRF = RandomForestRegressor(n_estimators=400, max_depth=20)\n",
    "modelXGB = XGBRegressor(colsample_bytree= 0.6, learning_rate= 0.05, max_depth= 8, n_estimators= 800)\n",
    "\n",
    "modelLR.fit(X_trainLR, y_trainLR)\n",
    "modelTree.fit(X_trainDT, y_trainDT)\n",
    "modelRF.fit(X_trainRF, y_trainRF)\n",
    "modelXGB.fit(X_trainXGB, y_trainXGB)\n",
    "\n",
    "predsLR = modelLR.predict(X_testLR)\n",
    "predsTree = modelTree.predict(X_testDT)\n",
    "predsRF = modelRF.predict(X_testRF)\n",
    "predsXGB = modelXGB.predict(X_testXGB)\n",
    "\n",
    "print(\"Linear Regresion\")\n",
    "print(\"Mean abs error:\",mean_absolute_error(y_testLR, predsLR))\n",
    "print(\"RMSE:\",mean_squared_error(y_testLR, predsLR, squared=False))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Decision Tree\")\n",
    "print(\"Mean abs error:\",mean_absolute_error(y_testDT, predsTree))\n",
    "print(\"RMSE:\",mean_squared_error(y_testDT, predsTree, squared=False))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Random Forest\")\n",
    "print(\"Mean abs error:\",mean_absolute_error(y_testRF, predsRF))\n",
    "print(\"RMSE:\",mean_squared_error(y_testRF, predsRF, squared=False))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"XGBoost\")\n",
    "print(\"Mean abs error:\",mean_absolute_error(y_testXGB, predsXGB))\n",
    "print(\"RMSE:\",mean_squared_error(y_testXGB, predsXGB, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize a part of the predictions against their true values\n",
    "\n",
    "plt.scatter(x = range(len(predsXGB)), y = (predsXGB - y_testXGB), marker='d')\n",
    "plt.scatter(x = range(len(predsXGB)), y = y_testXGB)\n",
    "plt.ylim((0,200))\n",
    "plt.xlim((100,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the indices of the undervalued properties threshold is: pred > 1.3 * value\n",
    "\n",
    "undervalued = []\n",
    "for i,pred in enumerate(predsXGB):\n",
    "    if pred > y_testXGB.values[i]*1.3:\n",
    "        undervalued.append(i)\n",
    "    \n",
    "print(\"there are\",len(undervalued),\"undervalued listings on AirBnB.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
